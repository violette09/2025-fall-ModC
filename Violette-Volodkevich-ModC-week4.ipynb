{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cd249e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Week 4 — Logistic Regression + Feature Scaling\n",
    "#Dataset: `carclaims 12.csv` | Target: `FraudFound`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d74b45da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, average_precision_score, confusion_matrix, roc_curve, precision_recall_curve\n",
    "\n",
    "df = pd.read_csv(\"carclaims 12.csv\")\n",
    "df.columns = [c.strip() for c in df.columns]\n",
    "target = \"FraudFound\"\n",
    "yraw = df[target]\n",
    "y = yraw if yraw.dtype!=object else yraw.astype(str).str.upper().map(\n",
    "    {\"Y\":1,\"YES\":1,\"1\":1,\"TRUE\":1,\"T\":1,\"N\":0,\"NO\":0,\"0\":0,\"FALSE\":0,\"F\":0}\n",
    ").astype(int)\n",
    "X = df.drop(columns=[target])\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,stratify=y,random_state=42)\n",
    "\n",
    "numeric = Pipeline([(\"impute\", SimpleImputer(strategy=\"median\")), (\"scale\", StandardScaler())])\n",
    "categorical = Pipeline([(\"impute\", SimpleImputer(strategy=\"most_frequent\")), (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))])\n",
    "pre = ColumnTransformer([(\"num\", numeric, num_cols), (\"cat\", categorical, cat_cols)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "781e4ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'clf__C': 1.0, 'clf__penalty': 'l1'}\n",
      "Accuracy: 0.940 | F1: 0.011 | ROC-AUC: 0.815 | PR-AUC: 0.179\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, average_precision_score\n",
    "\n",
    "# Quick pipeline\n",
    "pipe_fast = Pipeline([\n",
    "    (\"pre\", pre),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000, solver=\"liblinear\"))  # liblinear supports l1 & l2 and is faster\n",
    "])\n",
    "\n",
    "# Smaller grid (6 fits total × 3 folds = 18)\n",
    "param_fast = {\n",
    "    \"clf__penalty\": [\"l1\", \"l2\"],  # just two options\n",
    "    \"clf__C\": [0.1, 1.0, 10.0],    # small C grid\n",
    "}\n",
    "\n",
    "cv3 = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "gs_fast = GridSearchCV(pipe_fast, param_fast, scoring=\"roc_auc\", cv=cv3, n_jobs=-1, refit=True)\n",
    "\n",
    "# Fit\n",
    "gs_fast.fit(X_train, y_train)\n",
    "best = gs_fast.best_estimator_\n",
    "\n",
    "# Predict and evaluate\n",
    "proba = best.predict_proba(X_test)[:, 1]\n",
    "pred = (proba >= 0.5).astype(int)\n",
    "\n",
    "acc = accuracy_score(y_test, pred)\n",
    "f1  = f1_score(y_test, pred)\n",
    "auc = roc_auc_score(y_test, proba)\n",
    "ap  = average_precision_score(y_test, proba)\n",
    "\n",
    "print(\"Best parameters:\", gs_fast.best_params_)\n",
    "print(f\"Accuracy: {acc:.3f} | F1: {f1:.3f} | ROC-AUC: {auc:.3f} | PR-AUC: {ap:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b663b14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved plots to figs_wk4/\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"figs_wk4\", exist_ok=True)\n",
    "\n",
    "# ROC\n",
    "fpr, tpr, _ = roc_curve(y_test, proba)\n",
    "plt.figure(); plt.plot(fpr,tpr); plt.plot([0,1],[0,1],'--')\n",
    "plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\"); plt.title(\"Week 4 — ROC (Logistic)\")\n",
    "plt.savefig(\"figs_wk4/roc.png\", bbox_inches=\"tight\"); plt.close()\n",
    "\n",
    "# PR\n",
    "prec, rec, _ = precision_recall_curve(y_test, proba)\n",
    "plt.figure(); plt.plot(rec,prec)\n",
    "plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(\"Week 4 — Precision-Recall (Logistic)\")\n",
    "plt.savefig(\"figs_wk4/pr.png\", bbox_inches=\"tight\"); plt.close()\n",
    "\n",
    "# Confusion\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "plt.figure(); plt.imshow(cm)\n",
    "for (i,j),v in np.ndenumerate(cm): plt.text(j,i,str(v),ha='center',va='center')\n",
    "plt.title(\"Week 4 — Confusion Matrix (Logistic)\"); plt.xlabel(\"Predicted\"); plt.ylabel(\"Actual\")\n",
    "plt.savefig(\"figs_wk4/cm.png\", bbox_inches=\"tight\"); plt.close()\n",
    "\n",
    "print(\"Saved plots to figs_wk4/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c73bd92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
